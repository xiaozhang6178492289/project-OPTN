{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2306,
   "id": "177df59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-pandas in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.1 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from sklearn-pandas) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from sklearn-pandas) (1.20.3)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from sklearn-pandas) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from sklearn-pandas) (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->sklearn-pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->sklearn-pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->sklearn-pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23.0->sklearn-pandas) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\xiaoz\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23.0->sklearn-pandas) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn-pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# For preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper \n",
    "\n",
    "import torch # For building the networks \n",
    "import torchtuples as tt # Some useful functions\n",
    "# change pycox import datasets and df= read.csv\n",
    "\n",
    "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
    "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
    "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
    "from pycox.models import DeepHitSingle\n",
    "from pycox.evaluation import EvalSurv\n",
    "## Uncomment to install `sklearn-pandas`\n",
    "# ! pip install sklearn-pandas\n",
    "np.random.seed(1234)\n",
    "_ = torch.manual_seed(123)\n",
    "\n",
    "\n",
    "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
    "df_train['TBILI_TX']=df_train['TBILI_TX'].astype('float32')\n",
    "df_train['ALBUMIN_TX']=df_train['ALBUMIN_TX'].astype('float32')\n",
    "df_train['CMV_STATUS']=df_train['CMV_STATUS'].astype('float32')\n",
    "df_train['COLD_ISCH']=df_train['COLD_ISCH'].astype('float32')\n",
    "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
    "df_train['ETHCAT_DON']=df_train['ETHCAT_DON'].astype('float32')\n",
    "df_train['FINAL_INR']=df_train['FINAL_INR'].astype('float32')\n",
    "df_train['AGE']=df_train['AGE'].astype('float32')\n",
    "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
    "df_train['duration']=df_train['duration'].astype('float32')\n",
    "df_train['event']=df_train['event'].astype('int32')\n",
    "\n",
    "\n",
    "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
    "df_test['TBILI_TX']=df_test['TBILI_TX'].astype('float32')\n",
    "df_test['ALBUMIN_TX']=df_test['ALBUMIN_TX'].astype('float32')\n",
    "df_test['CMV_STATUS']=df_test['CMV_STATUS'].astype('float32')\n",
    "df_test['COLD_ISCH']=df_test['COLD_ISCH'].astype('float32')\n",
    "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
    "df_test['ETHCAT_DON']=df_test['ETHCAT_DON'].astype('float32')\n",
    "df_test['FINAL_INR']=df_test['FINAL_INR'].astype('float32')\n",
    "df_test['AGE']=df_test['AGE'].astype('float32')\n",
    "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
    "df_test['duration']=df_test['duration'].astype('float32')\n",
    "df_test['event']=df_test['event'].astype('int32')\n",
    "\n",
    "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
    "df_val['TBILI_TX']=df_val['TBILI_TX'].astype('float32')\n",
    "df_val['ALBUMIN_TX']=df_val['ALBUMIN_TX'].astype('float32')\n",
    "df_val['CMV_STATUS']=df_val['CMV_STATUS'].astype('float32')\n",
    "df_val['COLD_ISCH']=df_val['COLD_ISCH'].astype('float32')\n",
    "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
    "df_val['ETHCAT_DON']=df_val['ETHCAT_DON'].astype('float32')\n",
    "df_val['FINAL_INR']=df_val['FINAL_INR'].astype('float32')\n",
    "df_val['AGE']=df_val['AGE'].astype('float32')\n",
    "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
    "df_val['duration']=df_val['duration'].astype('float32')\n",
    "df_val['event']=df_val['event'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2307,
   "id": "888763e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class OrderedCategoricalLong:\n",
    "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
    "    i.e. index of category. Useful for entity embeddings.\n",
    "    Zero is reserved for unknown categories or nans.\n",
    "    Keyword Arguments:\n",
    "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
    "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
    "    \n",
    "    Returns:\n",
    "        [pd.Series] -- Series with long values reffering to categories.\n",
    "    \"\"\"\n",
    "    def __init__(self, min_per_category=20, return_series=False):\n",
    "        \n",
    "        self.min_per_category = min_per_category\n",
    "        self.return_series = return_series\n",
    "\n",
    "    def fit(self, series, y=None):\n",
    "        series = pd.Series(series).copy()\n",
    "        smaller = series.value_counts() < self.min_per_category\n",
    "        values = smaller[smaller].index.values\n",
    "        for v in values:\n",
    "            series[series == v] = np.nan\n",
    "        self.categories = series.astype('category').cat.categories\n",
    "        return self\n",
    "    \n",
    "    def transform(self, series, y=None):\n",
    "        series = pd.Series(series).copy()\n",
    "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
    "        transformed = pd.Series(transformed, index=series.index)\n",
    "        transformed = transformed.cat.codes.astype('int64') + 1\n",
    "        return transformed if self.return_series else transformed.values\n",
    "    \n",
    "    def fit_transform(self, series, y=None):\n",
    "        return self.fit(series, y).transform(series, y)\n",
    "cols_std = ['TBILI_TX','ALBUMIN_TX','COLD_ISCH', 'CREAT_TX','FINAL_INR','AGE'] # numeric variables\n",
    "cols_cat = ['TX_YEAR','CMV_STATUS','ETHCAT_DON','ETHCAT'] # categorical variables\n",
    "\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_std]\n",
    "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
    "\n",
    "x_mapper_float = DataFrameMapper(standardize)\n",
    "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
    "\n",
    "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
    "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
    "\n",
    "x_train = x_fit_transform(df_train)\n",
    "x_val = x_transform(df_val)\n",
    "x_test = x_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2308,
   "id": "3a9ef1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_durations = 10\n",
    "scheme = 'equidistant' # or quantiles\n",
    "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)\n",
    "\n",
    "# Plotting discrete intervals\n",
    "from pycox.utils import kaplan_meier\n",
    "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
    "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
    "plt.ylabel('S(t)')\n",
    "plt.legend()\n",
    "_ = plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2309,
   "id": "b3d4350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = x_train[1].max(0) + 1\n",
    "embedding_dims = num_embeddings // 2\n",
    "\n",
    "in_features = x_train[0].shape[1]\n",
    "out_features = labtrans.out_features\n",
    "num_nodes = [64, 32]\n",
    "batch_norm = True\n",
    "dropout = 0.7\n",
    "\n",
    "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
    "                                 num_nodes, out_features, batch_norm, dropout)\n",
    "                                 \n",
    "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
    "                            cycle_multiplier=2)\n",
    "\n",
    "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2310,
   "id": "4091fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1873817422860396"
      ]
     },
     "execution_count": 2310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size =1500\n",
    "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
    "lrfind.get_best_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2311,
   "id": "68c92d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.set_lr(0.187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2312,
   "id": "c704d05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_=lrfind.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2313,
   "id": "637b4e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 1.9331,\tval_loss: 11.5259\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 7.5589,\tval_loss: 13.7095\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 5.0437,\tval_loss: 4.1798\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 7.2965,\tval_loss: 0.9219\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.5630,\tval_loss: 0.7890\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 1.7521,\tval_loss: 0.6697\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 1.4335,\tval_loss: 0.6265\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 1.9947,\tval_loss: 0.6119\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 1.6454,\tval_loss: 0.5839\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 1.5280,\tval_loss: 0.5655\n",
      "10:\t[0s / 0s],\t\ttrain_loss: 1.0291,\tval_loss: 0.5578\n",
      "11:\t[0s / 0s],\t\ttrain_loss: 1.4583,\tval_loss: 0.5496\n",
      "12:\t[0s / 0s],\t\ttrain_loss: 2.0310,\tval_loss: 0.5472\n",
      "13:\t[0s / 0s],\t\ttrain_loss: 1.1623,\tval_loss: 0.5454\n",
      "14:\t[0s / 0s],\t\ttrain_loss: 1.0927,\tval_loss: 0.5427\n",
      "15:\t[0s / 0s],\t\ttrain_loss: 1.3568,\tval_loss: 0.5339\n",
      "16:\t[0s / 0s],\t\ttrain_loss: 0.9682,\tval_loss: 0.5306\n",
      "17:\t[0s / 0s],\t\ttrain_loss: 0.9740,\tval_loss: 0.5179\n",
      "18:\t[0s / 0s],\t\ttrain_loss: 0.9548,\tval_loss: 0.5101\n",
      "19:\t[0s / 0s],\t\ttrain_loss: 1.1836,\tval_loss: 0.5071\n",
      "20:\t[0s / 0s],\t\ttrain_loss: 1.1047,\tval_loss: 0.5078\n",
      "21:\t[0s / 0s],\t\ttrain_loss: 0.7300,\tval_loss: 0.5070\n",
      "22:\t[0s / 0s],\t\ttrain_loss: 0.8074,\tval_loss: 0.5025\n",
      "23:\t[0s / 0s],\t\ttrain_loss: 0.8606,\tval_loss: 0.5015\n",
      "24:\t[0s / 0s],\t\ttrain_loss: 0.8629,\tval_loss: 0.5005\n",
      "25:\t[0s / 0s],\t\ttrain_loss: 0.9444,\tval_loss: 0.4997\n",
      "26:\t[0s / 0s],\t\ttrain_loss: 0.9339,\tval_loss: 0.4990\n",
      "27:\t[0s / 0s],\t\ttrain_loss: 0.7519,\tval_loss: 0.4987\n",
      "28:\t[0s / 0s],\t\ttrain_loss: 0.7948,\tval_loss: 0.4986\n",
      "29:\t[0s / 0s],\t\ttrain_loss: 0.7392,\tval_loss: 0.4972\n",
      "30:\t[0s / 0s],\t\ttrain_loss: 0.8062,\tval_loss: 0.4975\n",
      "31:\t[0s / 0s],\t\ttrain_loss: 0.7599,\tval_loss: 0.4947\n",
      "32:\t[0s / 0s],\t\ttrain_loss: 0.7784,\tval_loss: 0.4931\n",
      "33:\t[0s / 0s],\t\ttrain_loss: 0.7279,\tval_loss: 0.4916\n",
      "34:\t[0s / 0s],\t\ttrain_loss: 0.6741,\tval_loss: 0.4906\n",
      "35:\t[0s / 0s],\t\ttrain_loss: 0.7441,\tval_loss: 0.4896\n",
      "36:\t[0s / 0s],\t\ttrain_loss: 0.7115,\tval_loss: 0.4880\n",
      "37:\t[0s / 0s],\t\ttrain_loss: 0.7441,\tval_loss: 0.4868\n",
      "38:\t[0s / 0s],\t\ttrain_loss: 0.9001,\tval_loss: 0.4855\n",
      "39:\t[0s / 0s],\t\ttrain_loss: 0.6970,\tval_loss: 0.4846\n",
      "40:\t[0s / 0s],\t\ttrain_loss: 0.7009,\tval_loss: 0.4833\n",
      "41:\t[0s / 0s],\t\ttrain_loss: 0.6380,\tval_loss: 0.4818\n",
      "42:\t[0s / 0s],\t\ttrain_loss: 0.6977,\tval_loss: 0.4802\n",
      "43:\t[0s / 0s],\t\ttrain_loss: 0.6990,\tval_loss: 0.4787\n",
      "44:\t[0s / 0s],\t\ttrain_loss: 0.6674,\tval_loss: 0.4779\n",
      "45:\t[0s / 0s],\t\ttrain_loss: 0.7022,\tval_loss: 0.4772\n",
      "46:\t[0s / 0s],\t\ttrain_loss: 0.6371,\tval_loss: 0.4764\n",
      "47:\t[0s / 0s],\t\ttrain_loss: 0.6937,\tval_loss: 0.4755\n",
      "48:\t[0s / 0s],\t\ttrain_loss: 0.6772,\tval_loss: 0.4753\n",
      "49:\t[0s / 0s],\t\ttrain_loss: 0.6356,\tval_loss: 0.4751\n",
      "50:\t[0s / 0s],\t\ttrain_loss: 0.6108,\tval_loss: 0.4755\n",
      "51:\t[0s / 0s],\t\ttrain_loss: 0.6739,\tval_loss: 0.4751\n",
      "52:\t[0s / 0s],\t\ttrain_loss: 0.6793,\tval_loss: 0.4748\n",
      "53:\t[0s / 0s],\t\ttrain_loss: 0.6549,\tval_loss: 0.4748\n",
      "54:\t[0s / 0s],\t\ttrain_loss: 0.6321,\tval_loss: 0.4750\n",
      "55:\t[0s / 0s],\t\ttrain_loss: 0.6558,\tval_loss: 0.4750\n",
      "56:\t[0s / 0s],\t\ttrain_loss: 0.6348,\tval_loss: 0.4749\n",
      "57:\t[0s / 0s],\t\ttrain_loss: 0.6494,\tval_loss: 0.4748\n",
      "58:\t[0s / 0s],\t\ttrain_loss: 0.6244,\tval_loss: 0.4749\n",
      "59:\t[0s / 0s],\t\ttrain_loss: 0.6141,\tval_loss: 0.4746\n",
      "60:\t[0s / 0s],\t\ttrain_loss: 0.6536,\tval_loss: 0.4743\n",
      "61:\t[0s / 0s],\t\ttrain_loss: 0.6763,\tval_loss: 0.4742\n",
      "62:\t[0s / 0s],\t\ttrain_loss: 0.6514,\tval_loss: 0.4744\n",
      "63:\t[0s / 0s],\t\ttrain_loss: 0.6284,\tval_loss: 0.4732\n",
      "64:\t[0s / 0s],\t\ttrain_loss: 0.6264,\tval_loss: 0.4720\n",
      "65:\t[0s / 0s],\t\ttrain_loss: 0.6576,\tval_loss: 0.4710\n",
      "66:\t[0s / 0s],\t\ttrain_loss: 0.6324,\tval_loss: 0.4698\n",
      "67:\t[0s / 0s],\t\ttrain_loss: 0.6099,\tval_loss: 0.4686\n",
      "68:\t[0s / 0s],\t\ttrain_loss: 0.6190,\tval_loss: 0.4678\n",
      "69:\t[0s / 0s],\t\ttrain_loss: 0.6192,\tval_loss: 0.4669\n",
      "70:\t[0s / 0s],\t\ttrain_loss: 0.6908,\tval_loss: 0.4661\n",
      "71:\t[0s / 0s],\t\ttrain_loss: 0.6297,\tval_loss: 0.4653\n",
      "72:\t[0s / 0s],\t\ttrain_loss: 0.6058,\tval_loss: 0.4650\n",
      "73:\t[0s / 0s],\t\ttrain_loss: 0.6193,\tval_loss: 0.4643\n",
      "74:\t[0s / 0s],\t\ttrain_loss: 0.5879,\tval_loss: 0.4635\n",
      "75:\t[0s / 0s],\t\ttrain_loss: 0.5952,\tval_loss: 0.4626\n",
      "76:\t[0s / 0s],\t\ttrain_loss: 0.5933,\tval_loss: 0.4619\n",
      "77:\t[0s / 0s],\t\ttrain_loss: 0.5519,\tval_loss: 0.4613\n",
      "78:\t[0s / 0s],\t\ttrain_loss: 0.6202,\tval_loss: 0.4612\n",
      "79:\t[0s / 0s],\t\ttrain_loss: 0.6350,\tval_loss: 0.4597\n",
      "80:\t[0s / 0s],\t\ttrain_loss: 0.6218,\tval_loss: 0.4596\n",
      "81:\t[0s / 0s],\t\ttrain_loss: 0.5621,\tval_loss: 0.4593\n",
      "82:\t[0s / 0s],\t\ttrain_loss: 0.6037,\tval_loss: 0.4587\n",
      "83:\t[0s / 0s],\t\ttrain_loss: 0.6310,\tval_loss: 0.4587\n",
      "84:\t[0s / 1s],\t\ttrain_loss: 0.5893,\tval_loss: 0.4584\n",
      "85:\t[0s / 1s],\t\ttrain_loss: 0.5965,\tval_loss: 0.4580\n",
      "86:\t[0s / 1s],\t\ttrain_loss: 0.5850,\tval_loss: 0.4579\n",
      "87:\t[0s / 1s],\t\ttrain_loss: 0.5816,\tval_loss: 0.4572\n",
      "88:\t[0s / 1s],\t\ttrain_loss: 0.5800,\tval_loss: 0.4565\n",
      "89:\t[0s / 1s],\t\ttrain_loss: 0.6001,\tval_loss: 0.4565\n",
      "90:\t[0s / 1s],\t\ttrain_loss: 0.5811,\tval_loss: 0.4559\n",
      "91:\t[0s / 1s],\t\ttrain_loss: 0.5971,\tval_loss: 0.4557\n",
      "92:\t[0s / 1s],\t\ttrain_loss: 0.5667,\tval_loss: 0.4558\n",
      "93:\t[0s / 1s],\t\ttrain_loss: 0.5648,\tval_loss: 0.4557\n",
      "94:\t[0s / 1s],\t\ttrain_loss: 0.5824,\tval_loss: 0.4561\n",
      "95:\t[0s / 1s],\t\ttrain_loss: 0.5694,\tval_loss: 0.4558\n",
      "96:\t[0s / 1s],\t\ttrain_loss: 0.5934,\tval_loss: 0.4557\n",
      "97:\t[0s / 1s],\t\ttrain_loss: 0.6224,\tval_loss: 0.4554\n",
      "98:\t[0s / 1s],\t\ttrain_loss: 0.5976,\tval_loss: 0.4555\n",
      "99:\t[0s / 1s],\t\ttrain_loss: 0.5751,\tval_loss: 0.4549\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
    "verbose = True \n",
    "\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2314,
   "id": "353e5946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2315,
   "id": "a7ea2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2316,
   "id": "a81fd79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
    "plt.ylabel('S(t | x)')\n",
    "_ = plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2317,
   "id": "db677a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = model.interpolate(10).predict_surv_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2318,
   "id": "f0a25129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
    "plt.ylabel('S(t | x)')\n",
    "_ = plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2319,
   "id": "277a5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2320,
   "id": "41e16d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7863636363636364"
      ]
     },
     "execution_count": 2320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.concordance_td('antolini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2372,
   "id": "53b9d620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_grid = np.linspace(durations_test.min(), durations_test.max(),4)\n",
    "ev.brier_score(time_grid).plot()\n",
    "plt.ylabel('Brier score')\n",
    "_ = plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2373,
   "id": "acc441bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ev.nbll(time_grid).plot()\n",
    "plt.ylabel('NBLL')\n",
    "_ = plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2374,
   "id": "30c456aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14739079332576357"
      ]
     },
     "execution_count": 2374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.integrated_brier_score(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2375,
   "id": "3726c481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4453589763547928"
      ]
     },
     "execution_count": 2375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.integrated_nbll(time_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "473cc290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =500\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.061)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "epochs = 130\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.3\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =500\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.073)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.3\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =300\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.0138)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.3\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =600\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.024)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =600\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.024)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =500\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.061)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =700\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.129)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =800\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.129)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1000\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.061)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "epochs = 30\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "epochs = 80\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =800\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.129)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "epochs = 80\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =700\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.129)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1000\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.061)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.3\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1000\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.061)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.6\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1000\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.155)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.6\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1300\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.0739)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1300\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.089)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1500\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.089)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =900\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.129)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.3\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1500\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.129)\n",
      "_=lr_finder.plot()\n",
      "_=lrfind.plot()\n",
      "model.optimizer.set_lr(0.050)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.3\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1500\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.01)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =950\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.01)\n",
      "_=lrfind.plot()\n",
      "model.optimizer.set_lr(0.035)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =850\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "_=lrfind.plot()\n",
      "model.optimizer.set_lr(0.089)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.3\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1600\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "_=lrfind.plot()\n",
      "model.optimizer.set_lr(0.001)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "model.optimizer.set_lr(0.107)\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1100\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.129)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1000\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.0613)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1200\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.0739)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1150\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.1072)\n",
      "_=lrfind.plot()\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1105\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.089)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1095\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.0739)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1098\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.1072)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1099\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.1072)\n",
      "model.optimizer.set_lr(0.0509)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1101\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.1291)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1100\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.1291)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1100\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.1291)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1000\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.0613)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1200\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.0739)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "! pip install sklearn-pandas\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "# For preprocessing\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn_pandas import DataFrameMapper \n",
      "\n",
      "import torch # For building the networks \n",
      "import torchtuples as tt # Some useful functions\n",
      "# change pycox import datasets and df= read.csv\n",
      "\n",
      "df_train=pd.read_csv('D:/UNOS_NEW/have_dephit_train_cindex.csv', sep=',')\n",
      "df_test=pd.read_csv('D:/UNOS_NEW/have_dephit_test_cindex.csv', sep=',')\n",
      "df_val=pd.read_csv('D:/UNOS_NEW/have_dephit_val_cindex.csv', sep=',')\n",
      "from pycox.models import DeepHitSingle\n",
      "from pycox.evaluation import EvalSurv\n",
      "## Uncomment to install `sklearn-pandas`\n",
      "# ! pip install sklearn-pandas\n",
      "np.random.seed(1234)\n",
      "_ = torch.manual_seed(123)\n",
      "\n",
      "df_train['DAYSWAIT_CHRON']=df_train['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_train['TX_YEAR']=df_train['TX_YEAR'].astype('float32')\n",
      "df_train['AGE']=df_train['AGE'].astype('float32')\n",
      "df_train['ETHCAT']=df_train['ETHCAT'].astype('float32')\n",
      "df_train['HCV_SEROSTATUS']=df_train['HCV_SEROSTATUS'].astype('float32')\n",
      "df_train['WORK_INCOME_TRR']=df_train['WORK_INCOME_TRR'].astype('float32')\n",
      "df_train['AGE_DON']=df_train['AGE_DON'].astype('float32')\n",
      "df_train['DIAG']=df_train['DIAG'].astype('float32')\n",
      "df_train['CREAT_TX']=df_train['CREAT_TX'].astype('float32')\n",
      "df_train['MED_COND_TRR']=df_train['MED_COND_TRR'].astype('float32')\n",
      "df_train['FUNC_STAT_TRR']=df_train['FUNC_STAT_TRR'].astype('float32')\n",
      "df_train['MACRO_FAT_GROUP']=df_train['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_train['duration']=df_train['duration'].astype('float32')\n",
      "df_train['event']=df_train['event'].astype('int32')\n",
      "\n",
      "df_test['DAYSWAIT_CHRON']=df_test['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_test['TX_YEAR']=df_test['TX_YEAR'].astype('float32')\n",
      "df_test['AGE']=df_test['AGE'].astype('float32')\n",
      "df_test['ETHCAT']=df_test['ETHCAT'].astype('float32')\n",
      "df_test['HCV_SEROSTATUS']=df_test['HCV_SEROSTATUS'].astype('float32')\n",
      "df_test['WORK_INCOME_TRR']=df_test['WORK_INCOME_TRR'].astype('float32')\n",
      "df_test['AGE_DON']=df_test['AGE_DON'].astype('float32')\n",
      "df_test['DIAG']=df_test['DIAG'].astype('float32')\n",
      "df_test['CREAT_TX']=df_test['CREAT_TX'].astype('float32')\n",
      "df_test['MED_COND_TRR']=df_test['MED_COND_TRR'].astype('float32')\n",
      "df_test['FUNC_STAT_TRR']=df_test['FUNC_STAT_TRR'].astype('float32')\n",
      "df_test['MACRO_FAT_GROUP']=df_test['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_test['duration']=df_test['duration'].astype('float32')\n",
      "df_test['event']=df_test['event'].astype('int32')\n",
      "\n",
      "df_val['DAYSWAIT_CHRON']=df_val['DAYSWAIT_CHRON'].astype('float32')\n",
      "df_val['TX_YEAR']=df_val['TX_YEAR'].astype('float32')\n",
      "df_val['AGE']=df_val['AGE'].astype('float32')\n",
      "df_val['ETHCAT']=df_val['ETHCAT'].astype('float32')\n",
      "df_val['HCV_SEROSTATUS']=df_val['HCV_SEROSTATUS'].astype('float32')\n",
      "df_val['WORK_INCOME_TRR']=df_val['WORK_INCOME_TRR'].astype('float32')\n",
      "df_val['AGE_DON']=df_val['AGE_DON'].astype('float32')\n",
      "df_val['DIAG']=df_val['DIAG'].astype('float32')\n",
      "df_val['CREAT_TX']=df_val['CREAT_TX'].astype('float32')\n",
      "df_val['MED_COND_TRR']=df_val['MED_COND_TRR'].astype('float32')\n",
      "df_val['FUNC_STAT_TRR']=df_val['FUNC_STAT_TRR'].astype('float32')\n",
      "df_val['MACRO_FAT_GROUP']=df_val['MACRO_FAT_GROUP'].astype('float32')\n",
      "df_val['duration']=df_val['duration'].astype('float32')\n",
      "df_val['event']=df_val['event'].astype('int32')\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "class OrderedCategoricalLong:\n",
      "    \"\"\"Transform pandas series or numpy array to categorical, and get (long) values,\n",
      "    i.e. index of category. Useful for entity embeddings.\n",
      "    Zero is reserved for unknown categories or nans.\n",
      "    Keyword Arguments:\n",
      "        min_per_category {int} -- Number of instances required to not be set to nan (default: {20})\n",
      "        return_series {bool} -- If return a array or pd.Series (default: {False})\n",
      "    \n",
      "    Returns:\n",
      "        [pd.Series] -- Series with long values reffering to categories.\n",
      "    \"\"\"\n",
      "    def __init__(self, min_per_category=20, return_series=False):\n",
      "        \n",
      "        self.min_per_category = min_per_category\n",
      "        self.return_series = return_series\n",
      "\n",
      "    def fit(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        smaller = series.value_counts() < self.min_per_category\n",
      "        values = smaller[smaller].index.values\n",
      "        for v in values:\n",
      "            series[series == v] = np.nan\n",
      "        self.categories = series.astype('category').cat.categories\n",
      "        return self\n",
      "    \n",
      "    def transform(self, series, y=None):\n",
      "        series = pd.Series(series).copy()\n",
      "        transformed = pd.Categorical(series, categories=self.categories, ordered=True)\n",
      "        transformed = pd.Series(transformed, index=series.index)\n",
      "        transformed = transformed.cat.codes.astype('int64') + 1\n",
      "        return transformed if self.return_series else transformed.values\n",
      "    \n",
      "    def fit_transform(self, series, y=None):\n",
      "        return self.fit(series, y).transform(series, y)\n",
      "cols_std = ['DAYSWAIT_CHRON','AGE','AGE_DON', 'CREAT_TX'] # numeric variables\n",
      "cols_cat = ['TX_YEAR','HCV_SEROSTATUS','DIAG','WORK_INCOME_TRR','MED_COND_TRR','FUNC_STAT_TRR','ETHCAT','MACRO_FAT_GROUP'] # categorical variables\n",
      "\n",
      "\n",
      "standardize = [([col], StandardScaler()) for col in cols_std]\n",
      "categorical = [(col, OrderedCategoricalLong()) for col in cols_cat]\n",
      "\n",
      "x_mapper_float = DataFrameMapper(standardize)\n",
      "x_mapper_long = DataFrameMapper(categorical)  # we need a separate mapper to convert data to 'int64'\n",
      "\n",
      "x_fit_transform = lambda df: tt.tuplefy(x_mapper_float.fit_transform(df), x_mapper_long.fit_transform(df))\n",
      "x_transform = lambda df: tt.tuplefy(x_mapper_float.transform(df), x_mapper_long.transform(df))\n",
      "\n",
      "x_train = x_fit_transform(df_train)\n",
      "x_val = x_transform(df_val)\n",
      "x_test = x_transform(df_test)\n",
      "num_durations = 10\n",
      "scheme = 'equidistant' # or quantiles\n",
      "labtrans = DeepHitSingle.label_transform(num_durations, scheme)\n",
      "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
      "y_train = labtrans.fit_transform(*get_target(df_train))\n",
      "y_val = labtrans.transform(*get_target(df_val))\n",
      "\n",
      "train = (x_train, y_train)\n",
      "val = (x_val, y_val)\n",
      "\n",
      "# We don't need to transform the test labels\n",
      "durations_test, events_test = get_target(df_test)\n",
      "\n",
      "# Plotting discrete intervals\n",
      "from pycox.utils import kaplan_meier\n",
      "plt.vlines(labtrans.cuts, 0, 1, colors='black', linestyles=\"--\", label='Discretization Grid')\n",
      "kaplan_meier(*get_target(df_train)).plot(label='Kaplan-Meier')\n",
      "plt.ylabel('S(t)')\n",
      "plt.legend()\n",
      "_ = plt.xlabel('Time')\n",
      "num_embeddings = x_train[1].max(0) + 1\n",
      "embedding_dims = num_embeddings // 2\n",
      "\n",
      "in_features = x_train[0].shape[1]\n",
      "out_features = labtrans.out_features\n",
      "num_nodes = [64, 64]\n",
      "batch_norm = True\n",
      "dropout = 0.4\n",
      "\n",
      "net = tt.practical.MixedInputMLP(in_features, num_embeddings, embedding_dims,\n",
      "                                 num_nodes, out_features, batch_norm, dropout)\n",
      "                                 \n",
      "optimizer = tt.optim.AdamWR(decoupled_weight_decay=0.01, cycle_eta_multiplier=0.8,\n",
      "                            cycle_multiplier=2)\n",
      "\n",
      "model = DeepHitSingle(net, optimizer, duration_index=labtrans.cuts)\n",
      "batch_size =1300\n",
      "lrfind = model.lr_finder(x_train, y_train, batch_size, tolerance=50)\n",
      "lrfind.get_best_lr()\n",
      "model.optimizer.set_lr(0.089)\n",
      "_=lrfind.plot()\n",
      "epochs = 100\n",
      "callbacks = [tt.cb.EarlyStoppingCycle()]\n",
      "verbose = True \n",
      "\n",
      "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
      "                val_data=val)\n",
      "_ = log.plot()\n",
      "surv = model.predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "surv = model.interpolate(10).predict_surv_df(x_test)\n",
      "surv.iloc[:, :5].plot(drawstyle='steps-post')\n",
      "plt.ylabel('S(t | x)')\n",
      "_ = plt.xlabel('Time')\n",
      "ev = EvalSurv(surv, durations_test, events_test, censor_surv='km')\n",
      "ev.concordance_td('antolini')\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385bbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
